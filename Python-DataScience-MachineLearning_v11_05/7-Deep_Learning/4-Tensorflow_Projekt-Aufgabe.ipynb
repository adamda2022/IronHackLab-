{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://akademie.datamics.com/kursliste/\">![title](bg_datamics_top.png)</a><center><em>© Datamics</em></center><br><center><em>Besuche uns für mehr Informationen auf <a href='https://akademie.datamics.com/kursliste/'>www.akademie.datamics.com</a></em>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tensorflow Projekt - Aufgaben\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "Achtung dieses Notebook läuft nur mit der alten Tensorflow V1 </div>\n",
    "\n",
    "Wir werden nun mit unserem Tensorflow Projekt den Deep Learning Abschnitt abschließen. Dazu schauen wir uns die Effizienz von Deep Neural Nets an!\n",
    "\n",
    "Wir werden einen [Bank Authentifizierungs Datensatz](https://archive.ics.uci.edu/ml/datasets/banknote+authentication) aus dem USI Repository verwenden.\n",
    "\n",
    "Der Datensatz beinhaltet 5 Spalten:\n",
    "\n",
    "* variance of Wavelet Transformed image (continuous)\n",
    "* skewness of Wavelet Transformed image (continuous)\n",
    "* curtosis of Wavelet Transformed image (continuous)\n",
    "* entropy of image (continuous)\n",
    "* class (integer)\n",
    "\n",
    "Hier gibt \"class\" an, ob eine Banknote authentifiziert wurde oder nicht. \n",
    "\n",
    "Diese Art von Aufgabe ist perfekt für Neuronale Netze und Deep Learning! Folge den Anweisungen und löse die Aufgaben. Viel Spaß!\n",
    "\n",
    "## Die Daten Laden\n",
    "\n",
    "**Nutze Pandas, um die `bank_note_data.csv` Datei aus diesem verzeichnis zu öffnen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Schaue dir den head des DataFrames an.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explorative Daten Analyse\n",
    "\n",
    "Wir erzeugen einige Visualisierungen für einen allgemeinen Überblick:\n",
    "\n",
    "**Importiere Seaborn und setzte matplotlib inline.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle ein `countplot` für die \"Classes\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dein Code hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle ein `pairplot` und setze die `hue` zu Class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dein Code hier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Daten Vorbereitung\n",
    "\n",
    "Wenn wir Neuronale Netze und Deep Learning basierte Systeme nutzen, dann empfiehlt es sich üblicherweise die Daten zu Standardisieren. Dieser Schritt ist für unseren konkreten Datensatz nicht nötig, wir möchten aber doch einmal gemeinsam durchgehen.\n",
    "\n",
    "### Standard Scaling\n",
    "\n",
    "**Importiere `StandardScaler` aus `sklearn.preprocessing`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle ein StandardScaler() Objekt namens \"scaler\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fitte scaler auf die Features.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nutze die `transform()` Methode, um die Features in eine skalierte Version umzuwandeln.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Konvertiere die skalierten Features in einen DataFrame und sieh dir dessen Head an.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split\n",
    "\n",
    "**Erstelle zwei Objekte X und y, die die skalierten Feature-Werte und Labels beinhalten.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nutze die `to_numpy()` Methode auf X und y und überschreibe sie mit dem neuen Ergebnis.**\n",
    "\n",
    "*Wir müssen dies tun, da Tensorflow mit Numpy Arrays arbeitet anstatt mit Pandas Series.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nutze SciKit Learn, um Trainings- und Testsets zu erzeugen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Contrib.learn\n",
    "\n",
    "**Importiere `tesnorflow.contrib.learn` als \"learn\".**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Erstelle ein Objekt namens \"Classifier\", das ein `DNNClassifier` aus learn ist. Setze `classes` auf 2  und `hidden_units` auf [10,20,10].** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jetzt fitte den classfier auf das Trainingsset. Nutze `steps=200` und `batch_size=20`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modell Auswertung\n",
    "\n",
    "**Nutze die `predict` Methode, um Vorhersagen für X_test zu erstellen.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Jetzt erstelle Callsification Report und Confusion Matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optionaler Vergleich\n",
    "\n",
    "Dir sollten extrem akkurae Ergebnisse beim DNN Modell auffallen. Vergleichen wir das mit einem Random Forest Classifier für eine Einordnung der Ergebnisse.\n",
    "\n",
    "**Nutze SciKit Learn, um einen Random Forest Classifier zu erstellen. Vergleiche anschließend Classification Report und Confusion Matrix.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es sollte auch ziemlich gut, aber nicht genauso gut wie das DNN Modell abgeschnitten haben. Das hat dir hoffentlich die Power der DNNs gezeigt.\n",
    "\n",
    "# Gut gemacht!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
